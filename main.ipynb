{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/agent/anaconda3/envs/astro/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: /home/agent/anaconda3/envs/astro/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torch\n",
    "import wandb\n",
    "import utils.utils as ut\n",
    "# Ensure deterministic behavior\n",
    "torch.backends.cudnn.deterministic = True\n",
    "random.seed(hash(\"setting random seeds\") % 2**32 - 1)\n",
    "np.random.seed(hash(\"improves reproducibility\") % 2**32 - 1)\n",
    "torch.manual_seed(hash(\"by removing stochasticity\") % 2**32 - 1)\n",
    "torch.cuda.manual_seed_all(hash(\"so runs are repeatable\") % 2**32 - 1)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# remove slow mirror from list of MNIST mirrors\n",
    "torchvision.datasets.MNIST.mirrors = [mirror for mirror in torchvision.datasets.MNIST.mirrors\n",
    "                                      if not mirror.startswith(\"http://yann.lecun.com\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbradipo\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "wandb version 0.13.6 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/agent/Documents/GitHub/pytorch_lesson_sweeps/wandb/run-20221211_102842-30v3431b</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/bradipo/wandb-basic-lesson/runs/30v3431b\" target=\"_blank\">test01</a></strong> to <a href=\"https://wandb.ai/bradipo/wandb-basic-lesson\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvNet(\n",
      "  (layer1): Sequential(\n",
      "    (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (fc): Linear(in_features=1568, out_features=10, bias=True)\n",
      ")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be7c68d78a4b4315ba127e2cbc6dfdf5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after 03072 examples: 0.542\n",
      "Loss after 06272 examples: 0.209\n",
      "Loss after 09472 examples: 0.479\n",
      "Loss after 12640 examples: 0.103\n",
      "Loss after 15840 examples: 0.224\n",
      "Loss after 19040 examples: 0.039\n",
      "Loss after 22240 examples: 0.181\n",
      "Loss after 25408 examples: 0.097\n",
      "Loss after 28608 examples: 0.042\n",
      "Loss after 31808 examples: 0.081\n",
      "Loss after 35008 examples: 0.062\n",
      "Loss after 38176 examples: 0.059\n",
      "Loss after 41376 examples: 0.056\n",
      "Loss after 44576 examples: 0.043\n",
      "Loss after 47776 examples: 0.090\n",
      "Loss after 50944 examples: 0.038\n",
      "Loss after 54144 examples: 0.049\n",
      "Loss after 57344 examples: 0.016\n",
      "Loss after 60512 examples: 0.009\n",
      "Loss after 63712 examples: 0.011\n",
      "Loss after 66912 examples: 0.007\n",
      "Loss after 70112 examples: 0.012\n",
      "Loss after 73280 examples: 0.034\n",
      "Loss after 76480 examples: 0.029\n",
      "Loss after 79680 examples: 0.023\n",
      "Loss after 82880 examples: 0.041\n",
      "Loss after 86048 examples: 0.007\n",
      "Loss after 89248 examples: 0.023\n",
      "Loss after 92448 examples: 0.005\n",
      "Loss after 95648 examples: 0.004\n",
      "Loss after 98816 examples: 0.002\n",
      "Loss after 102016 examples: 0.020\n",
      "Loss after 105216 examples: 0.026\n",
      "Loss after 108384 examples: 0.002\n",
      "Loss after 111584 examples: 0.001\n",
      "Loss after 114784 examples: 0.008\n",
      "Loss after 117984 examples: 0.001\n",
      "Loss after 121152 examples: 0.001\n",
      "Loss after 124352 examples: 0.019\n",
      "Loss after 127552 examples: 0.022\n",
      "Loss after 130752 examples: 0.047\n",
      "Loss after 133920 examples: 0.009\n",
      "Loss after 137120 examples: 0.044\n",
      "Loss after 140320 examples: 0.000\n",
      "Loss after 143520 examples: 0.033\n",
      "Loss after 146688 examples: 0.008\n",
      "Loss after 149888 examples: 0.001\n",
      "Loss after 153088 examples: 0.002\n",
      "Loss after 156256 examples: 0.001\n",
      "Loss after 159456 examples: 0.001\n",
      "Loss after 162656 examples: 0.000\n",
      "Loss after 165856 examples: 0.002\n",
      "Loss after 169024 examples: 0.001\n",
      "Loss after 172224 examples: 0.001\n",
      "Loss after 175424 examples: 0.001\n",
      "Loss after 178624 examples: 0.034\n",
      "Loss after 181792 examples: 0.001\n",
      "Loss after 184992 examples: 0.008\n",
      "Loss after 188192 examples: 0.047\n",
      "Loss after 191392 examples: 0.000\n",
      "Loss after 194560 examples: 0.002\n",
      "Loss after 197760 examples: 0.000\n",
      "Loss after 200960 examples: 0.000\n",
      "Loss after 204128 examples: 0.000\n",
      "Loss after 207328 examples: 0.000\n",
      "Loss after 210528 examples: 0.000\n",
      "Loss after 213728 examples: 0.002\n",
      "Loss after 216896 examples: 0.001\n",
      "Loss after 220096 examples: 0.047\n",
      "Loss after 223296 examples: 0.000\n",
      "Loss after 226496 examples: 0.007\n",
      "Loss after 229664 examples: 0.002\n",
      "Loss after 232864 examples: 0.000\n",
      "Loss after 236064 examples: 0.035\n",
      "Loss after 239264 examples: 0.027\n",
      "Accuracy of the model on the 2000 test images: 98.500000%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2003b9015885411cb854028aac6b6ad0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.212 MB of 0.217 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.974102…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>loss</td><td>█▄▂▁▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▂▁▁▁</td></tr><tr><td>test_accuracy</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>19</td></tr><tr><td>loss</td><td>0.02734</td></tr><tr><td>test_accuracy</td><td>0.985</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">test01</strong>: <a href=\"https://wandb.ai/bradipo/wandb-basic-lesson/runs/30v3431b\" target=\"_blank\">https://wandb.ai/bradipo/wandb-basic-lesson/runs/30v3431b</a><br/>Synced 6 W&B file(s), 225 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221211_102842-30v3431b/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "config = dict(\n",
    "    epochs=20,\n",
    "    classes=10,\n",
    "    kernels=[16, 32],\n",
    "    batch_size=128,\n",
    "    learning_rate=0.005,\n",
    "    dataset=\"MNIST\",\n",
    "    architecture=\"CNN\",\n",
    "    name='test01',\n",
    "    entity='bradipo',\n",
    "    project='wandb-basic-lesson')\n",
    "\n",
    "model = ut.model_pipeline(config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "astro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "21b039ccd75659c49c4abcfb1776e487d1f65aa0e7fe27f26549f6fad379afe8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
